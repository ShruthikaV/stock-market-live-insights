%matplotlib inline


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import datetime





#data = pd.read_csv(r'C:\Users\Shruthika\OneDrive\Documents\sem 7\Unified projects\Stock data\TCS_stock_action.csv')
data_history = pd.read_csv(r'C:\Users\Shruthika\OneDrive\Documents\sem 7\Unified projects\Stock data\TCS_stock_history.csv')
data_history['Date'] = pd.to_datetime(data_history['Date'], format='%d/%m/%Y')
data_history.sort_values(by='Date', inplace=True)
data_history.head()


#Null Values
print(data_history.isnull().sum())


data_history.info()


data_history['Open'] = pd.to_numeric(data_history['Open'], errors='coerce')
data_history['High'] = pd.to_numeric(data_history['High'], errors='coerce')
data_history['Low'] = pd.to_numeric(data_history['Low'], errors='coerce')
data_history['Close'] = pd.to_numeric(data_history['Close'], errors='coerce')


data.ffill(inplace=True)


data_history.head()


#Converting into datetime and sorting in ascending values
data_history['Date'] = pd.to_datetime(data_history['Date'])
data_history = data_history.sort_values(by='Date')


data_history.describe()





corel = data_history.corr()
corel


#Correlation of features with the target variable
correlation_with_close = data_history.corr()['Close'].sort_values(ascending=False)
print(correlation_with_close)


sns.heatmap(data_history.corr(),annot= True,cmap= "Greens",fmt=".2f")
plt.show()





plt.figure(figsize=(14, 7))
plt.plot(data_history['Date'], data_history['Close'], color='blue', label='Close Price')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('TCS Stock Close Price Over Time', weight = "bold")
plt.legend()
plt.show()





plt.figure(figsize=(14, 7))
plt.plot(data_history['Date'], data_history['Open'], color='purple', label='Open Price')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('TCS Stock Open Price Over Time')
plt.legend()
plt.show() 





plt.figure(figsize=(12, 6))
plt.plot(data_history['Date'], data_history['Volume'], label='Volume', color='g')
plt.plot(data_history['Date'], data_history['Dividends'], label='Dividends',
color='r')
plt.plot(data_history['Date'], data_history['Stock Splits'], label='Stock Splits',
color='m')
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Volume, Dividends and Stock Splits over Time', weight = "bold")
plt.legend()
plt.show()





plt.scatter(data_history['Close'], data_history['Volume'])
plt.xlabel('Close Price')
plt.ylabel('Volume')
plt.title('Close Price vs. Volume',weight= "bold")
plt.show()





plt.scatter(data_history['Dividends'], data_history['Close'])
plt.xlabel('Dividends')
plt.ylabel('Close Price')
plt.title('Dividends vs. Close Price')
plt.show()





plt.scatter(data_history['Stock Splits'], data_history['Close'])
plt.xlabel('Stock Splits')
plt.ylabel('Close Price' )
plt.title('Stock Splits vs. Close Price' )
plt.show()





data_history['MA50'] = data_history['Close'].rolling(window=50).mean()
data_history['MA200'] = data_history['Close'].rolling(window=200).mean()


data_history['Short_MA'] = data_history['Close'].rolling(window=5).mean()
data_history['Long_MA'] = data_history['Close'].rolling(window=30).mean()

# Creating a trading signals based on moving average crossovers
data_history['Signal'] = np.where(data_history['Short_MA'] > data_history['Long_MA'], 1, -1)

# Plot the strategy signals
plt.figure(figsize=(12, 6))
plt.plot(data_history['Date'], data_history['Close'], label='Close Price', color='b')
plt.plot(data_history['Date'], data_history['Short_MA'], label='Short-term MA', color='r')
plt.plot(data_history['Date'], data_history['Long_MA'], label='Long-term MA', color='g')
plt.scatter(data_history['Date'], data_history['Close'] * data_history['Signal'], label='Buy/Sell Signal', marker='o', color='m')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Moving Average Crossover Strategy')
plt.legend()
plt.show()


Moving Averages


data_history['30-Day Moving Avg'] = data_history['Close'].rolling(window=30).mean()

# Plot Close price and moving average
plt.figure(figsize=(12, 6))
plt.plot(data_history['Date'], data_history['Close'], label='Close Price', color='b')
plt.plot(data_history['Date'], data_history['30-Day Moving Avg'], label='30-Day Moving Avg', color='r')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Close Price and 30-Day Moving Average' )
plt.legend()
plt.show()








data_history['Daily_Price_Change'] = data_history['Close'].pct_change() * 100 
# Distribution of daily percentage change
plt.figure(figsize=(8, 6))
sns.histplot(data_history['Daily_Price_Change'].dropna(), kde=True, color='orange')
plt.xlabel('Daily Percentage Change')
plt.ylabel('Frequency')
plt.title('Distribution of Daily Percentage Change')
plt.show()





data_history['Moving_Avg_Close'] = data_history['Close'].rolling(window=7).mean()


# Prepare the data for LSTM
X_train = data_history['Close'].values.reshape(-1, 1)
y_train = data_history['Close'].shift(-1).dropna().values

# Normalize the data
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Define the test data
test_ratio = 0.2
test_size = int(len(data_history) * test_ratio)
test_data = data_history[-test_size:]

# Prepare the data for prediction
X_test = test_data['Close'].values.reshape(-1, 1)
X_test_scaled = scaler.transform(X_test)
X_test_lstm = X_test_scaled.reshape(-1, 1, 1)

#Resahping the data for LSTM
X_train_lstm = X_train_scaled[ :- 1].reshape(-1, 1,1)
y_train_lstm = X_train_scaled[1:]





from keras.models import Sequential
from keras.layers import LSTM, Dense

model = Sequential()
model.add(LSTM(50, input_shape=(1, 1)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')

# Set the number of epochs and batch size
epochs = 30
batch_size = 15

# Train the model with tqdm progress bar
for epoch in tqdm(range(epochs)):
    for i in range(0, len(X_train_lstm), batch_size):
        X_batch = X_train_lstm[i:i+batch_size]

y_batch = y_train_lstm[i:i+batch_size]
model.train_on_batch(X_batch, y_batch)

# Prepare the data for prediction
X_test = test_data['Close'].values.reshape(-1, 1)
X_test_scaled = scaler.transform(X_test)
X_test_lstm = X_test_scaled.reshape(-1, 1, 1)





lstm_predictions = model.predict(X_test_lstm).flatten()

#Inverse transform of the predictions
lstm_predictions = lstm_predictions.reshape(-1, 1)
lstm_predictions = scaler.inverse_transform(lstm_predictions)

#Visualization of LSTM predictions

plt.figure(figsize=(12, 6))
plt.plot(test_data['Date'], test_data['Close'], label='Actual Close Price', color='b')
plt.plot(test_data['Date'], lstm_predictions, label='Predicted Close Price (LSTM)', color='r')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Actual vs. Predicted Close Price using LSTM')
plt.legend()
plt.show()





lstm_predictions = lstm_predictions.reshape(-1, 1)
lstm_predictions = scaler.inverse_transform(lstm_predictions)
date_index = test_data.index[-len(lstm_predictions):]

predictions_df = pd.DataFrame({'Date': date_index, 'Predicted_Close': lstm_predictions.flatten()})
predictions_df.to_csv('predictions.csv', index=False)



